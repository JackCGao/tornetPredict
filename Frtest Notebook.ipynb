{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPh3-ZS9WDF9"
      },
      "outputs": [],
      "source": [
        "# s TornadoModel project\n",
        "import sys\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# Now import tornet modules\n",
        "from tornet.data.constants import ALL_VARIABLES\n",
        "from tornet.data.loader import read_file, TornadoDataLoader\n",
        "from tornet.data.preprocess import add_coordinates, remove_time_dim, permute_dims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "Eb3LEBnqkxJS",
        "outputId": "2e600928-3458-44bd-ce47-a0cdf7594911"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "# Path to your local dataset root\n",
        "data_root = '/Users/jackgao/Downloads/TornadoModel/zenodo_download'\n",
        "\n",
        "data_type = 'train'  # or 'test'\n",
        "years = [2022]\n",
        "\n",
        "# Load and filter the catalog\n",
        "catalog_path = os.path.join(data_root, 'catalog.csv')\n",
        "if not os.path.exists(catalog_path):\n",
        "    raise RuntimeError('Unable to find catalog.csv at ' + data_root)\n",
        "\n",
        "catalog = pd.read_csv(catalog_path, parse_dates=['start_time', 'end_time'])\n",
        "catalog = catalog[catalog['type'] == data_type]\n",
        "catalog = catalog[catalog.start_time.dt.year.isin(years)]\n",
        "catalog = catalog.sample(frac=1, random_state=1234)  # Shuffle rows\n",
        "\n",
        "# Construct full file paths\n",
        "file_list = [os.path.join(data_root, f) for f in catalog.filename]\n",
        "\n",
        "# Define your dataset\n",
        "class TornadoDataset(TornadoDataLoader, Dataset):\n",
        "    pass\n",
        "\n",
        "# If you already removed the time dimension\n",
        "transform = transforms.Compose([\n",
        "    lambda d: add_coordinates(d, include_az=False, tilt_last=False, backend=torch)\n",
        "])\n",
        "\n",
        "# Instantiate dataset\n",
        "torch_ds = TornadoDataset(\n",
        "    file_list,\n",
        "    variables=ALL_VARIABLES,\n",
        "    n_frames=1,\n",
        "    tilt_last=False,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "# DataLoader\n",
        "batch_size = 32\n",
        "torch_dl = torch.utils.data.DataLoader(\n",
        "    torch_ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Fk7P9kS9WGaC"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List, Tuple, Any\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics import MetricCollection\n",
        "import lightning as L\n",
        "\n",
        "from tornet.models.torch.coordconv import CoordConv2D\n",
        "from tornet.data.constants import CHANNEL_MIN_MAX, ALL_VARIABLES\n",
        "\n",
        "\n",
        "class TornadoClassifier(L.LightningModule):\n",
        "    \"\"\"\n",
        "    Fits tornado classifier\n",
        "    \"\"\"\n",
        "    def __init__(self,model:nn.Module,\n",
        "                      lr:float=1e-3,\n",
        "                      lr_decay_rate=0.9,\n",
        "                      lr_decay_steps=1,\n",
        "                      label_smoothing:float=0.2,\n",
        "                      weight_decay:float=0.001,\n",
        "                      metrics:MetricCollection=None):\n",
        "        super().__init__()\n",
        "        self.model=model\n",
        "        self.lr=lr\n",
        "        self.label_smoothing=label_smoothing\n",
        "        self.weight_decay=weight_decay\n",
        "        self.lr_decay_rate=lr_decay_rate\n",
        "        self.lr_decay_steps=lr_decay_steps\n",
        "        self.loss = nn.CrossEntropyLoss(label_smoothing=0.2)\n",
        "\n",
        "        if metrics:\n",
        "            self.train_metrics = metrics.clone(prefix='train_')\n",
        "            self.valid_metrics = metrics.clone(prefix='val_')\n",
        "            self.test_metrics = metrics.clone(prefix='test_')\n",
        "        else:\n",
        "            self.train_metrics=self.valid_metrics=self.test_metrics=None\n",
        "\n",
        "    def forward(self,batch):\n",
        "        return self.model(batch)\n",
        "\n",
        "    def training_step(self, batch, _):\n",
        "        y = torch.squeeze(batch.pop('label')) # [batch]\n",
        "        logits = self.model(batch) # [batch,1,L,W]\n",
        "        logits = F.max_pool2d(logits, kernel_size=logits.size()[2:]) # [batch,1,1,1]\n",
        "        logits = torch.cat( (-logits,logits),axis=1)  # [batch,2,1,1]\n",
        "        logits = torch.squeeze(logits) # [batch,2] for binary classification\n",
        "        loss = self.loss(logits, y)\n",
        "\n",
        "        # Logging..\n",
        "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        if self.train_metrics:\n",
        "            met_out = self.train_metrics(logits[:,1],y)\n",
        "            self.log_dict(met_out, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self,batch,_):\n",
        "        y,logits,loss=self._shared_eval(batch)\n",
        "\n",
        "        # Logging..\n",
        "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        if self.valid_metrics:\n",
        "            self._log_metrics(self.valid_metrics,y,logits)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self,batch,_):\n",
        "        y,logits,loss=self._shared_eval(batch)\n",
        "\n",
        "        # Logging..\n",
        "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        if self.test_metrics:\n",
        "            self._log_metrics(self.test_metrics,y,logits)\n",
        "        return loss\n",
        "\n",
        "    def _shared_eval(self,batch):\n",
        "        y = torch.squeeze(batch.pop('label')) # [batch]\n",
        "        logits = self.model(batch) # [batch,1,L,W]\n",
        "        logits = F.max_pool2d(logits, kernel_size=logits.size()[2:]) # [batch,1,1,1]\n",
        "        logits = torch.cat( (-logits,logits),axis=1)  # [batch,2,1,1]\n",
        "        logits = torch.squeeze(logits) # [batch,2] for binary classification\n",
        "        loss = self.loss(logits, y)\n",
        "        return y,logits,loss\n",
        "\n",
        "    def _log_metrics(self,metrics,y,logits):\n",
        "        met_out = metrics(logits[:,1],y)\n",
        "        self.log_dict(met_out, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(),\n",
        "                               lr=self.lr,\n",
        "                               weight_decay=self.weight_decay)\n",
        "\n",
        "        # Define the learning rate scheduler\n",
        "        scheduler = {\n",
        "            'scheduler': StepLR(optimizer,\n",
        "                                step_size=self.lr_decay_steps,\n",
        "                                gamma=self.lr_decay_rate),\n",
        "            'interval': 'epoch',  # Adjust the learning rate at the end of each epoch\n",
        "            'frequency': 1  # Apply the scheduler every epoch\n",
        "        }\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "\n",
        "class TornadoLikelihood(nn.Module):\n",
        "    \"\"\"\n",
        "    Produces 2D tornado likelihood field\n",
        "    \"\"\"\n",
        "    def __init__(self,  shape:Tuple[int]=(2,120,240),\n",
        "                        c_shape:Tuple[int]=(2,120,240),\n",
        "                        input_variables:List[str]=ALL_VARIABLES,\n",
        "                        start_filters:int=64,\n",
        "                        background_flag:float=-3.0,\n",
        "                        include_range_folded:bool=True):\n",
        "        super(TornadoLikelihood, self).__init__()\n",
        "        self.input_shape=shape\n",
        "        self.n_sweeps=shape[0]\n",
        "        self.c_shape=c_shape\n",
        "        self.input_variables=input_variables\n",
        "        self.start_filters=start_filters\n",
        "        self.background_flag=background_flag\n",
        "        self.include_range_folded=include_range_folded\n",
        "\n",
        "        # Set up normalizers\n",
        "        self.input_norm_layers = {}\n",
        "        for v in input_variables:\n",
        "            min_max = np.array(CHANNEL_MIN_MAX[v]) # [2,]\n",
        "            scale = 1/(min_max[1]-min_max[0])\n",
        "            offset = min_max[0]\n",
        "            self.input_norm_layers[v] = NormalizeVariable(scale,offset)\n",
        "\n",
        "        # Processing blocks\n",
        "        in_channels = (len(input_variables)+int(self.include_range_folded))*self.n_sweeps\n",
        "        in_coords=self.c_shape[0]\n",
        "        self.blk1 = VggBlock(in_channels,in_coords,start_filters,   kernel_size=3,  n_convs=2, drop_rate=0.1)   # (60,120)\n",
        "        self.blk2 = VggBlock(start_filters,in_coords,2*start_filters, kernel_size=3,  n_convs=2, drop_rate=0.1)  # (30,60)\n",
        "        self.blk3 = VggBlock(2*start_filters,in_coords,4*start_filters, kernel_size=3,  n_convs=3, drop_rate=0.1)  # (15,30)\n",
        "        self.blk4 = VggBlock(4*start_filters,in_coords,8*start_filters, kernel_size=3,  n_convs=3, drop_rate=0.1)  # (7,15)\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8*start_filters, out_channels=512, kernel_size=(1,1)),\n",
        "             nn.ReLU(),\n",
        "             nn.Conv2d(in_channels=512, out_channels=256, kernel_size=(1,1)),\n",
        "             nn.ReLU()\n",
        "        )\n",
        "        self.conv_out = nn.Conv2d(in_channels=256, out_channels=1, kernel_size=(1,1))\n",
        "\n",
        "\n",
        "    def _normalize_inputs(self,data):\n",
        "        normed_data = {}\n",
        "        for v in self.input_variables:\n",
        "            normed_data[v] = self.input_norm_layers[v](data[v])\n",
        "        return normed_data\n",
        "\n",
        "    def forward(self,data: Dict[str,Any]):\n",
        "        \"\"\"\n",
        "        Assumes data contains radar varialbes on [batch,tilt,az,rng]\n",
        "        and coordinate tensor\n",
        "        \"\"\"\n",
        "        # extract inputs\n",
        "        x = {v:data[v] for v in self.input_variables} # each [batch,tilt,Az,Rng]\n",
        "        c = data['coordinates']\n",
        "\n",
        "        # normalize\n",
        "        x = self._normalize_inputs(x) # each [batch,tilt,Az,Rng]\n",
        "\n",
        "        # concatenate along channel (tilt) dim\n",
        "        x = torch.cat([x[v] for v in self.input_variables],axis=1) #  [batch,tilt*len(input_variables)*2,Az,Rng]\n",
        "\n",
        "        # Remove nan's\n",
        "        x = torch.where(torch.isnan(x),self.background_flag,x)\n",
        "\n",
        "        # concat range_Folded mask\n",
        "        if self.include_range_folded:\n",
        "            x = torch.cat((x,data['range_folded_mask']),axis=1)\n",
        "\n",
        "        # process\n",
        "        x,c=self.blk1((x,c))\n",
        "        x,c=self.blk2((x,c))\n",
        "        x,c=self.blk3((x,c))\n",
        "        x,c=self.blk4((x,c))\n",
        "        x = self.head(x)\n",
        "\n",
        "        # output single channel heatmap for likelihood field\n",
        "        x = self.conv_out(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class NormalizeVariable(nn.Module):\n",
        "    \"\"\"\n",
        "    Normalize input tensor as (X-offset)*scale\n",
        "    \"\"\"\n",
        "    def __init__(self, scale, offset):\n",
        "        super(NormalizeVariable, self).__init__()\n",
        "        self.register_buffer('scale', torch.tensor(scale))\n",
        "        self.register_buffer('offset', torch.tensor(offset))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return (x - self.offset) * self.scale\n",
        "\n",
        "\n",
        "class VggBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Processing block based on VGG19, with coord conv layers\n",
        "    \"\"\"\n",
        "    def __init__(self, input_image_channels,\n",
        "                       input_coordinate_channels,\n",
        "                       n_output_channels,\n",
        "                       kernel_size=3,\n",
        "                       n_convs=3,\n",
        "                       drop_rate=0.1):\n",
        "        super(VggBlock, self).__init__()\n",
        "        self.input_image_channels=input_image_channels\n",
        "        self.input_coordinate_channels=input_coordinate_channels\n",
        "        self.n_output_channels=n_output_channels\n",
        "        self.kernel_size=kernel_size\n",
        "        self.n_convs=n_convs\n",
        "        self.drop_rate=drop_rate\n",
        "\n",
        "        self.steps = []\n",
        "        for k in range(n_convs):\n",
        "            if k==0:\n",
        "                in_channels=input_image_channels\n",
        "            else:\n",
        "                in_channels=n_output_channels\n",
        "            self.steps.append(CoordConv2D(in_image_channels=in_channels,\n",
        "                                          in_coord_channels=input_coordinate_channels,\n",
        "                                          out_channels=n_output_channels,\n",
        "                                          kernel_size=kernel_size,\n",
        "                                          padding='same',\n",
        "                                          activation='relu'))\n",
        "        self.conv_block = nn.Sequential(*self.steps)\n",
        "        self.mx=nn.MaxPool2d(2, stride=2)\n",
        "        self.mc=nn.MaxPool2d(2, stride=2)\n",
        "        if drop_rate>0:\n",
        "            self.drop=nn.Dropout(p=drop_rate)\n",
        "        else:\n",
        "            self.drop=None\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x,c=inputs\n",
        "        x,c=self.conv_block((x,c))\n",
        "        x=self.mx(x)\n",
        "        c=self.mc(c)\n",
        "        if self.drop:\n",
        "            x=self.drop(x)\n",
        "        return x,c\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZkTm_Xu5WI2B"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/jackgao/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "\n",
            "  | Name          | Type              | Params | Mode \n",
            "------------------------------------------------------------\n",
            "0 | model         | TornadoLikelihood | 8.1 M  | train\n",
            "1 | loss          | CrossEntropyLoss  | 0      | train\n",
            "2 | train_metrics | MetricCollection  | 0      | train\n",
            "3 | valid_metrics | MetricCollection  | 0      | train\n",
            "4 | test_metrics  | MetricCollection  | 0      | train\n",
            "------------------------------------------------------------\n",
            "8.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "8.1 M     Total params\n",
            "32.337    Total estimated model params size (MB)\n",
            "70        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/Users/jackgao/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
            "/Users/jackgao/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92739cff5edc4d94afdac03c755d3dad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "IndexError",
          "evalue": "too many indices for array: array is 3-dimensional, but 4 were indexed",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m trainer = L.Trainer(limit_train_batches=\u001b[32m10\u001b[39m, max_epochs=\u001b[32m3\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mtype\u001b[39m(torch_dl)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dl\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     51\u001b[39m     _call_teardown_hook(trainer)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    592\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    602\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.register_signal_handlers()\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1017\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1054\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_sanity_check()\n\u001b[32m   1055\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1058\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.state\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    215\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end()\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trainer.profiler.profile(\u001b[33m\"\u001b[39m\u001b[33mrun_training_epoch\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/training_epoch_loop.py:152\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m         \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/training_epoch_loop.py:306\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    305\u001b[39m     dataloader_iter = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     batch, _, __ = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m     \u001b[38;5;66;03m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[39;00m\n\u001b[32m    308\u001b[39m     \u001b[38;5;66;03m# fetcher state so that the batch_idx is correct after restarting\u001b[39;00m\n\u001b[32m    309\u001b[39m     batch_idx = \u001b[38;5;28mself\u001b[39m.batch_idx + \u001b[32m1\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fetchers.py:134\u001b[39m, in \u001b[36m_PrefetchDataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    131\u001b[39m         \u001b[38;5;28mself\u001b[39m.done = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batches\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     batch = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fetchers.py:61\u001b[39m, in \u001b[36m_DataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mself\u001b[39m._start_profiler()\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28mself\u001b[39m.done = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/lightning/pytorch/utilities/combined_loader.py:341\u001b[39m, in \u001b[36mCombinedLoader.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> _ITERATOR_RETURN:\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     out = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._iterator, _Sequential):\n\u001b[32m    343\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/lightning/pytorch/utilities/combined_loader.py:78\u001b[39m, in \u001b[36m_MaxSizeCycle.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         out[i] = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28mself\u001b[39m._consumed[i] = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/.venv/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornet/tornet/data/loader.py:161\u001b[39m, in \u001b[36mTornadoDataLoader.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m,index:\u001b[38;5;28mint\u001b[39m):\n\u001b[32m    158\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m    Reads file at index\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     data = \u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfile_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mtilt_last\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtilt_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mn_frames\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_frames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n\u001b[32m    167\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.transform(data)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornet/tornet/data/loader.py:51\u001b[39m, in \u001b[36mread_file\u001b[39m\u001b[34m(f, variables, n_frames, tilt_last)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m xr.open_dataset(f) \u001b[38;5;28;01mas\u001b[39;00m ds:\n\u001b[32m     48\u001b[39m     \n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# Load each radar variable\u001b[39;00m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m variables:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m         data[v]=\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[43mn_frames\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m     \u001b[38;5;66;03m# Various numeric metadata\u001b[39;00m\n\u001b[32m     54\u001b[39m     data[\u001b[33m'\u001b[39m\u001b[33mrange_folded_mask\u001b[39m\u001b[33m'\u001b[39m] = ds[\u001b[33m'\u001b[39m\u001b[33mrange_folded_mask\u001b[39m\u001b[33m'\u001b[39m].values[-n_frames:,:,:,:].astype(np.float32) \u001b[38;5;66;03m# only two channels for vel,width\u001b[39;00m\n",
            "\u001b[31mIndexError\u001b[39m: too many indices for array: array is 3-dimensional, but 4 were indexed"
          ]
        }
      ],
      "source": [
        "# Train this model using torch lightning\n",
        "import lightning as L\n",
        "import torchmetrics\n",
        "from torchmetrics import MetricCollection\n",
        "from tornet.models.torch.cnn_baseline import TornadoClassifier\n",
        "\n",
        "# Metrics expected to be binary classification metrics that expect (logits,label)\n",
        "#    where logits and label are both (N,) tensors\n",
        "#    e.g. torchmetrics.classification.BinaryAccuracy\n",
        "metrics = MetricCollection([\n",
        "            torchmetrics.classification.BinaryAccuracy(),\n",
        "            torchmetrics.classification.BinaryAUROC(),\n",
        "            torchmetrics.classification.BinaryAveragePrecision()\n",
        "        ])\n",
        "\n",
        "cnn = TornadoLikelihood()\n",
        "classifier = TornadoClassifier(cnn,metrics=metrics)\n",
        "\n",
        "# Low number of train_batches/epochs only for demo purposes\n",
        "trainer = L.Trainer(limit_train_batches=10, max_epochs=3)\n",
        "type(torch_dl)\n",
        "\n",
        "trainer.fit(classifier, train_dataloaders=torch_dl)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
