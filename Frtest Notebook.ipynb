{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "MPh3-ZS9WDF9"
      },
      "outputs": [],
      "source": [
        "# s TornadoModel project\n",
        "import sys\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# Now import tornet modules\n",
        "from tornet.data.constants import ALL_VARIABLES\n",
        "from tornet.data.loader import read_file, TornadoDataLoader\n",
        "from tornet.data.preprocess import add_coordinates, remove_time_dim, permute_dims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "Eb3LEBnqkxJS",
        "outputId": "2e600928-3458-44bd-ce47-a0cdf7594911"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "# Path to your local dataset root\n",
        "data_root = '/Users/jackgao/Downloads/data'\n",
        "\n",
        "data_type = 'train'  # or 'test'\n",
        "years = [2013, 2014]\n",
        "\n",
        "# Load and filter the catalog\n",
        "catalog_path = os.path.join(data_root, 'catalog.csv')\n",
        "if not os.path.exists(catalog_path):\n",
        "    raise RuntimeError('Unable to find catalog.csv at ' + data_root)\n",
        "\n",
        "catalog = pd.read_csv(catalog_path, parse_dates=['start_time', 'end_time'])\n",
        "catalog = catalog[catalog['type'] == data_type]\n",
        "catalog = catalog[catalog.start_time.dt.year.isin(years)]\n",
        "catalog = catalog.sample(frac=1, random_state=1234)  # Shuffle rows\n",
        "\n",
        "# Construct full file paths\n",
        "file_list = [os.path.join(data_root, f) for f in catalog.filename]\n",
        "\n",
        "# Define your dataset\n",
        "class TornadoDataset(TornadoDataLoader, Dataset):\n",
        "    pass\n",
        "\n",
        "# If you already removed the time dimension\n",
        "transform = transforms.Compose([\n",
        "    lambda d: add_coordinates(d, include_az=False, tilt_last=False, backend=torch)\n",
        "])\n",
        "\n",
        "# Instantiate dataset\n",
        "torch_ds = TornadoDataset(\n",
        "    file_list,\n",
        "    variables=ALL_VARIABLES,\n",
        "    n_frames=1,\n",
        "    tilt_last=False,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "# DataLoader\n",
        "batch_size = 32\n",
        "torch_dl = torch.utils.data.DataLoader(\n",
        "    torch_ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Fk7P9kS9WGaC"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "DISTRIBUTION STATEMENT A. Approved for public release. Distribution is unlimited.\n",
        "\n",
        "This material is based upon work supported by the Department of the Air Force under Air Force Contract No. FA8702-15-D-0001. Any opinions, findings, conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the Department of the Air Force.\n",
        "\n",
        "Â© 2024 Massachusetts Institute of Technology.\n",
        "\n",
        "\n",
        "The software/firmware is provided to you on an As-Is basis\n",
        "\n",
        "Delivered to the U.S. Government with Unlimited Rights, as defined in DFARS Part 252.227-7013 or 7014 (Feb 2014). Notwithstanding any copyright notice, U.S. Government rights in this work are defined by DFARS 252.227-7013 or DFARS 252.227-7014 as detailed above. Use of this work other than as specifically authorized by the U.S. Government may violate any copyrights that exist in this work.\n",
        "\"\"\"\n",
        "\n",
        "from typing import Dict, List, Tuple, Any\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics import MetricCollection\n",
        "import lightning as L\n",
        "\n",
        "from tornet.models.torch.coordconv import CoordConv2D\n",
        "from tornet.data.constants import CHANNEL_MIN_MAX, ALL_VARIABLES\n",
        "\n",
        "\n",
        "class TornadoClassifier(L.LightningModule):\n",
        "    \"\"\"\n",
        "    Fits tornado classifier\n",
        "    \"\"\"\n",
        "    def __init__(self,model:nn.Module,\n",
        "                      lr:float=1e-3,\n",
        "                      lr_decay_rate=0.9,\n",
        "                      lr_decay_steps=1,\n",
        "                      label_smoothing:float=0.2,\n",
        "                      weight_decay:float=0.001,\n",
        "                      metrics:MetricCollection=None):\n",
        "        super().__init__()\n",
        "        self.model=model\n",
        "        self.lr=lr\n",
        "        self.label_smoothing=label_smoothing\n",
        "        self.weight_decay=weight_decay\n",
        "        self.lr_decay_rate=lr_decay_rate\n",
        "        self.lr_decay_steps=lr_decay_steps\n",
        "        self.loss = nn.CrossEntropyLoss(label_smoothing=0.2)\n",
        "\n",
        "        if metrics:\n",
        "            self.train_metrics = metrics.clone(prefix='train_')\n",
        "            self.valid_metrics = metrics.clone(prefix='val_')\n",
        "            self.test_metrics = metrics.clone(prefix='test_')\n",
        "        else:\n",
        "            self.train_metrics=self.valid_metrics=self.test_metrics=None\n",
        "\n",
        "    def forward(self,batch):\n",
        "        return self.model(batch)\n",
        "        \n",
        "    def training_step(self, batch, _):\n",
        "        y = torch.squeeze(batch.pop('label')) # [batch]\n",
        "        logits = self.model(batch) # [batch,1,L,W] \n",
        "        logits = F.max_pool2d(logits, kernel_size=logits.size()[2:]) # [batch,1,1,1] \n",
        "        logits = torch.cat( (-logits,logits),axis=1)  # [batch,2,1,1] \n",
        "        logits = torch.squeeze(logits) # [batch,2] for binary classification\n",
        "        loss = self.loss(logits, y)\n",
        "        \n",
        "        # Logging..\n",
        "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        if self.train_metrics:\n",
        "            met_out = self.train_metrics(logits[:,1],y)\n",
        "            self.log_dict(met_out, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self,batch,_):\n",
        "        y,logits,loss=self._shared_eval(batch)\n",
        "        \n",
        "        # Logging..\n",
        "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        if self.valid_metrics:\n",
        "            self._log_metrics(self.valid_metrics,y,logits)\n",
        "        return loss\n",
        "    \n",
        "    def test_step(self,batch,_):\n",
        "        y,logits,loss=self._shared_eval(batch)\n",
        "        \n",
        "        # Logging..\n",
        "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        if self.test_metrics:\n",
        "            self._log_metrics(self.test_metrics,y,logits)\n",
        "        return loss\n",
        "\n",
        "    def _shared_eval(self,batch):\n",
        "        y = torch.squeeze(batch.pop('label')) # [batch]\n",
        "        logits = self.model(batch) # [batch,1,L,W] \n",
        "        logits = F.max_pool2d(logits, kernel_size=logits.size()[2:]) # [batch,1,1,1] \n",
        "        logits = torch.cat( (-logits,logits),axis=1)  # [batch,2,1,1] \n",
        "        logits = torch.squeeze(logits) # [batch,2] for binary classification\n",
        "        loss = self.loss(logits, y)\n",
        "        return y,logits,loss\n",
        "    \n",
        "    def _log_metrics(self,metrics,y,logits):\n",
        "        met_out = metrics(logits[:,1],y)\n",
        "        self.log_dict(met_out, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), \n",
        "                               lr=self.lr,\n",
        "                               weight_decay=self.weight_decay)\n",
        "        \n",
        "        # Define the learning rate scheduler\n",
        "        scheduler = {\n",
        "            'scheduler': StepLR(optimizer, \n",
        "                                step_size=self.lr_decay_steps, \n",
        "                                gamma=self.lr_decay_rate),\n",
        "            'interval': 'epoch',  # Adjust the learning rate at the end of each epoch\n",
        "            'frequency': 1  # Apply the scheduler every epoch\n",
        "        }\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "\n",
        "class TornadoLikelihood(nn.Module):\n",
        "    \"\"\"\n",
        "    Produces 2D tornado likelihood field\n",
        "    \"\"\"\n",
        "    def __init__(self,  shape:Tuple[int]=(2,120,240),\n",
        "                        c_shape:Tuple[int]=(2,120,240),\n",
        "                        input_variables:List[str]=ALL_VARIABLES,\n",
        "                        start_filters:int=64,\n",
        "                        background_flag:float=-3.0,\n",
        "                        include_range_folded:bool=True):\n",
        "        super(TornadoLikelihood, self).__init__()\n",
        "        self.input_shape=shape\n",
        "        self.n_sweeps=shape[0]\n",
        "        self.c_shape=c_shape\n",
        "        self.input_variables=input_variables\n",
        "        self.start_filters=start_filters\n",
        "        self.background_flag=background_flag\n",
        "        self.include_range_folded=include_range_folded\n",
        "        \n",
        "        # Set up normalizers\n",
        "        self.input_norm_layers = {}\n",
        "        for v in input_variables:\n",
        "            min_max = np.array(CHANNEL_MIN_MAX[v]) # [2,]\n",
        "            scale = 1/(min_max[1]-min_max[0])\n",
        "            offset = min_max[0]\n",
        "            self.input_norm_layers[v] = NormalizeVariable(scale,offset)\n",
        "            \n",
        "        # Processing blocks\n",
        "        in_channels = (len(input_variables)+int(self.include_range_folded))*self.n_sweeps\n",
        "        in_coords=self.c_shape[0]\n",
        "        self.blk1 = VggBlock(in_channels,in_coords,start_filters,   kernel_size=3,  n_convs=2, drop_rate=0.1)   # (60,120)\n",
        "        self.blk2 = VggBlock(start_filters,in_coords,2*start_filters, kernel_size=3,  n_convs=2, drop_rate=0.1)  # (30,60)\n",
        "        self.blk3 = VggBlock(2*start_filters,in_coords,4*start_filters, kernel_size=3,  n_convs=3, drop_rate=0.1)  # (15,30)\n",
        "        self.blk4 = VggBlock(4*start_filters,in_coords,8*start_filters, kernel_size=3,  n_convs=3, drop_rate=0.1)  # (7,15)\n",
        "        \n",
        "        self.head = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8*start_filters, out_channels=512, kernel_size=(1,1)),\n",
        "             nn.ReLU(),\n",
        "             nn.Conv2d(in_channels=512, out_channels=256, kernel_size=(1,1)),\n",
        "             nn.ReLU()\n",
        "        )\n",
        "        self.conv_out = nn.Conv2d(in_channels=256, out_channels=1, kernel_size=(1,1))\n",
        "        \n",
        "        \n",
        "    def _normalize_inputs(self,data):\n",
        "        normed_data = {}\n",
        "        for v in self.input_variables:\n",
        "            normed_data[v] = self.input_norm_layers[v](data[v])\n",
        "        return normed_data\n",
        "    \n",
        "    def forward(self,data: Dict[str,Any]):\n",
        "        \"\"\"\n",
        "        Assumes data contains radar varialbes on [batch,tilt,az,rng]\n",
        "        and coordinate tensor\n",
        "        \"\"\"\n",
        "        # extract inputs\n",
        "        x = {v:data[v] for v in self.input_variables} # each [batch,tilt,Az,Rng]\n",
        "        c = data['coordinates']\n",
        "        \n",
        "        # normalize\n",
        "        x = self._normalize_inputs(x) # each [batch,tilt,Az,Rng]\n",
        "        \n",
        "        # concatenate along channel (tilt) dim\n",
        "        x = torch.cat([x[v] for v in self.input_variables],axis=1) #  [batch,tilt*len(input_variables)*2,Az,Rng]\n",
        "        \n",
        "        # Remove nan's\n",
        "        x = torch.where(torch.isnan(x),self.background_flag,x)\n",
        "        \n",
        "        # concat range_Folded mask\n",
        "        if self.include_range_folded:\n",
        "            x = torch.cat((x,data['range_folded_mask']),axis=1)\n",
        "        \n",
        "        # process\n",
        "        x,c=self.blk1((x,c))\n",
        "        x,c=self.blk2((x,c))\n",
        "        x,c=self.blk3((x,c))\n",
        "        x,c=self.blk4((x,c))\n",
        "        x = self.head(x)\n",
        "\n",
        "        # output single channel heatmap for likelihood field\n",
        "        x = self.conv_out(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class NormalizeVariable(nn.Module):\n",
        "    \"\"\"\n",
        "    Normalize input tensor as (X-offset)*scale\n",
        "    \"\"\"\n",
        "    def __init__(self, scale, offset):\n",
        "        super(NormalizeVariable, self).__init__()\n",
        "        self.register_buffer('scale', torch.tensor(scale))\n",
        "        self.register_buffer('offset', torch.tensor(offset))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return (x - self.offset) * self.scale\n",
        "\n",
        "\n",
        "class VggBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Processing block based on VGG19, with coord conv layers\n",
        "    \"\"\"\n",
        "    def __init__(self, input_image_channels,\n",
        "                       input_coordinate_channels,\n",
        "                       n_output_channels,\n",
        "                       kernel_size=3,\n",
        "                       n_convs=3,\n",
        "                       drop_rate=0.1):\n",
        "        super(VggBlock, self).__init__()\n",
        "        self.input_image_channels=input_image_channels\n",
        "        self.input_coordinate_channels=input_coordinate_channels\n",
        "        self.n_output_channels=n_output_channels\n",
        "        self.kernel_size=kernel_size\n",
        "        self.n_convs=n_convs\n",
        "        self.drop_rate=drop_rate\n",
        "\n",
        "        self.steps = []\n",
        "        for k in range(n_convs):\n",
        "            if k==0:\n",
        "                in_channels=input_image_channels\n",
        "            else:\n",
        "                in_channels=n_output_channels\n",
        "            self.steps.append(CoordConv2D(in_image_channels=in_channels,\n",
        "                                          in_coord_channels=input_coordinate_channels,\n",
        "                                          out_channels=n_output_channels, \n",
        "                                          kernel_size=kernel_size,\n",
        "                                          padding='same',\n",
        "                                          activation='relu'))\n",
        "        self.conv_block = nn.Sequential(*self.steps)\n",
        "        self.mx=nn.MaxPool2d(2, stride=2)\n",
        "        self.mc=nn.MaxPool2d(2, stride=2)\n",
        "        if drop_rate>0:\n",
        "            self.drop=nn.Dropout(p=drop_rate)\n",
        "        else:\n",
        "            self.drop=None\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x,c=inputs\n",
        "        x,c=self.conv_block((x,c))\n",
        "        x=self.mx(x)\n",
        "        c=self.mc(c)\n",
        "        if self.drop:\n",
        "            x=self.drop(x)\n",
        "        return x,c\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkTm_Xu5WI2B"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ð¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/jackgao/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "\n",
            "  | Name          | Type              | Params | Mode \n",
            "------------------------------------------------------------\n",
            "0 | model         | TornadoLikelihood | 8.1 M  | train\n",
            "1 | loss          | CrossEntropyLoss  | 0      | train\n",
            "2 | train_metrics | MetricCollection  | 0      | train\n",
            "3 | valid_metrics | MetricCollection  | 0      | train\n",
            "4 | test_metrics  | MetricCollection  | 0      | train\n",
            "------------------------------------------------------------\n",
            "8.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "8.1 M     Total params\n",
            "32.337    Total estimated model params size (MB)\n",
            "70        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/Users/jackgao/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
            "/Users/jackgao/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "996b945a454f4a53bf866df79f21d322",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "linspace() received an invalid combination of arguments - got (numpy.ndarray, numpy.ndarray, int), but expected one of:\n * (Tensor start, Tensor end, int steps, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (Number start, Tensor end, int steps, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (Tensor start, Number end, int steps, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (Number start, Number end, int steps, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Low number of train_batches/epochs only for demo purposes\u001b[39;00m\n\u001b[32m     22\u001b[39m trainer = L.Trainer(limit_train_batches=\u001b[32m10\u001b[39m, max_epochs=\u001b[32m3\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dl\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     51\u001b[39m     _call_teardown_hook(trainer)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    592\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    602\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.register_signal_handlers()\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1017\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1054\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_sanity_check()\n\u001b[32m   1055\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1058\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.state\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    215\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end()\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trainer.profiler.profile(\u001b[33m\"\u001b[39m\u001b[33mrun_training_epoch\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/training_epoch_loop.py:152\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m         \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/training_epoch_loop.py:306\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    305\u001b[39m     dataloader_iter = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     batch, _, __ = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m     \u001b[38;5;66;03m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[39;00m\n\u001b[32m    308\u001b[39m     \u001b[38;5;66;03m# fetcher state so that the batch_idx is correct after restarting\u001b[39;00m\n\u001b[32m    309\u001b[39m     batch_idx = \u001b[38;5;28mself\u001b[39m.batch_idx + \u001b[32m1\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fetchers.py:134\u001b[39m, in \u001b[36m_PrefetchDataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    131\u001b[39m         \u001b[38;5;28mself\u001b[39m.done = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batches\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     batch = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fetchers.py:61\u001b[39m, in \u001b[36m_DataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mself\u001b[39m._start_profiler()\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28mself\u001b[39m.done = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/lightning/pytorch/utilities/combined_loader.py:341\u001b[39m, in \u001b[36mCombinedLoader.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> _ITERATOR_RETURN:\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     out = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._iterator, _Sequential):\n\u001b[32m    343\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/lightning/pytorch/utilities/combined_loader.py:78\u001b[39m, in \u001b[36m_MaxSizeCycle.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         out[i] = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28mself\u001b[39m._consumed[i] = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/tornet/data/loader.py:167\u001b[39m, in \u001b[36mTornadoDataLoader.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    161\u001b[39m data = read_file(\u001b[38;5;28mself\u001b[39m.file_list[index],\n\u001b[32m    162\u001b[39m                  variables=\u001b[38;5;28mself\u001b[39m.variables,\n\u001b[32m    163\u001b[39m                  tilt_last=\u001b[38;5;28mself\u001b[39m.tilt_last,\n\u001b[32m    164\u001b[39m                  n_frames=\u001b[38;5;28mself\u001b[39m.n_frames)\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/.venv/lib/python3.13/site-packages/torchvision/transforms/transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(d)\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# If you already removed the time dimension\u001b[39;00m\n\u001b[32m     31\u001b[39m transform = transforms.Compose([\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m d: \u001b[43madd_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_az\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtilt_last\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m ])\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Instantiate dataset\u001b[39;00m\n\u001b[32m     36\u001b[39m torch_ds = TornadoDataset(\n\u001b[32m     37\u001b[39m     file_list,\n\u001b[32m     38\u001b[39m     variables=ALL_VARIABLES,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     transform=transform\n\u001b[32m     42\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/tornet/data/preprocess.py:30\u001b[39m, in \u001b[36madd_coordinates\u001b[39m\u001b[34m(d, min_range_m, include_az, tilt_last, backend)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_coordinates\u001b[39m(d,min_range_m=\u001b[32m2125.0\u001b[39m,\n\u001b[32m     27\u001b[39m                     include_az=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     28\u001b[39m                     tilt_last=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     29\u001b[39m                     backend=np):\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     c=\u001b[43mcompute_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmin_range_m\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_range_m\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m                    \u001b[49m\u001b[43minclude_az\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_az\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mtilt_last\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtilt_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     d[\u001b[33m'\u001b[39m\u001b[33mcoordinates\u001b[39m\u001b[33m'\u001b[39m]=c\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m d\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/TornadoModel/tornetPredict/tornet/data/preprocess.py:71\u001b[39m, in \u001b[36mcompute_coordinates\u001b[39m\u001b[34m(d, min_range_m, include_az, tilt_last, backend)\u001b[39m\n\u001b[32m     68\u001b[39m az_upper = (\u001b[32m90\u001b[39m-az_upper) * np.pi/\u001b[32m180\u001b[39m \u001b[38;5;66;03m# [1,]\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# create mesh grids \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m az = \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43maz_lower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43maz_upper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m rg = backend.linspace( rng_lower, rng_upper, shape[\u001b[32m1\u001b[39m] )\n\u001b[32m     73\u001b[39m R,A = backend.meshgrid(rg,az,indexing=\u001b[33m'\u001b[39m\u001b[33mxy\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mTypeError\u001b[39m: linspace() received an invalid combination of arguments - got (numpy.ndarray, numpy.ndarray, int), but expected one of:\n * (Tensor start, Tensor end, int steps, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (Number start, Tensor end, int steps, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (Tensor start, Number end, int steps, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (Number start, Number end, int steps, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"
          ]
        }
      ],
      "source": [
        "# Train this model using torch lightning\n",
        "import lightning as L\n",
        "import torchmetrics\n",
        "from torchmetrics import MetricCollection\n",
        "from tornet.models.torch.cnn_baseline import TornadoClassifier\n",
        "# Metrics expected to be binary classification metrics that expect (logits,label)\n",
        "#    where logits and label are both (N,) tensors \n",
        "#    e.g. torchmetrics.classification.BinaryAccuracy\n",
        "metrics = MetricCollection([\n",
        "            torchmetrics.classification.BinaryAccuracy(), \n",
        "            torchmetrics.classification.BinaryAUROC(), \n",
        "            torchmetrics.classification.BinaryAveragePrecision()\n",
        "        ])\n",
        "\n",
        "cnn = TornadoLikelihood()\n",
        "classifier = TornadoClassifier(cnn,metrics=metrics)\n",
        "\n",
        "# Low number of train_batches/epochs only for demo purposes\n",
        "trainer = L.Trainer(limit_train_batches=10, max_epochs=3)\n",
        "trainer.fit(classifier,train_dataloaders=torch_dl)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
